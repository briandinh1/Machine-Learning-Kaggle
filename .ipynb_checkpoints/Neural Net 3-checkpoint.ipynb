{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-864080469a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mXe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/X_test.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ml' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mltools as ml;\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.loadtxt('data/X_train.txt')\n",
    "Y = np.loadtxt('data/Y_train.txt')\n",
    "Xe = np.loadtxt('data/X_test.txt')\n",
    "\n",
    "Xt,Xv,Yt,Yv = ml.splitData(X,Y,0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "Xt_new = scaler.transform(Xt)\n",
    "Xv_new = scaler.transform(Xv)\n",
    "X_new = scaler.transform(X)\n",
    "Xe_new = scaler.transform(Xe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# You should monitor its performance, preferably on both training & validation data, during backpropagation, \n",
    "# and verify that the training process is working properly and converging to a reasonable performance value \n",
    "# (e.g., comparably to other methods).  Start with few layers (2-3) and moderate numbers of hidden nodes (100-1000) per layer; \n",
    "# within these settings you can work to make sure your model is training adequately.\n",
    "\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(100,100,100), activation='logistic', solver='adam', max_iter=5000, shuffle=True, \n",
    "#                     learning_rate='invscaling', learning_rate_init=0.0001, power_t=0.5, tol=1e-6, verbose=True, \n",
    "#                     early_stopping=True)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(200,200,200), activation='tanh', solver='adam', max_iter=500, shuffle=True, \n",
    "                    learning_rate_init=0.0001, tol=1e-6, verbose=True, early_stopping=False)\n",
    "\n",
    "clf.fit(X_new,Y)\n",
    "#clf.fit(Xt_new,Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print 'Training Score =',clf.score(Xt_new,Yt)\n",
    "Ytpred = clf.predict_proba(Xt_new)\n",
    "print 'Training AUC =',roc_auc_score(Yt, Ytpred[:,1])\n",
    "# print\n",
    "# print 'Validation Score =',clf.score(Xv_new,Yv)\n",
    "Yvpred = clf.predict_proba(Xv_new)\n",
    "'Validation AUC =',roc_auc_score(Yv, Yvpred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YtePred = clf.predict_proba(Xe_new)[:,1]\n",
    "np.savetxt('Yhat_NNet3.txt',\n",
    "    np.vstack( (np.arange(len(YtePred)) , YtePred) ).T,\n",
    "    '%d, %.2f',header='ID,Prob1',comments='',delimiter=',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
